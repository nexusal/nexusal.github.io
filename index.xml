<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dive into nexus of everything</title>
    <link>https://nexusal.github.io/</link>
    <description>Recent content on Dive into nexus of everything</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Aug 2020 09:30:00 +0800</lastBuildDate>
    
	<atom:link href="https://nexusal.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>根据产品的工艺规格产量, 运用聚类算法划分生产线</title>
      <link>https://nexusal.github.io/%E8%81%9A%E7%B1%BB/%E7%94%9F%E4%BA%A7%E7%BA%BF%E8%81%9A%E7%B1%BB/</link>
      <pubDate>Mon, 10 Aug 2020 09:30:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/%E8%81%9A%E7%B1%BB/%E7%94%9F%E4%BA%A7%E7%BA%BF%E8%81%9A%E7%B1%BB/</guid>
      <description>图片如果太小, 可以右击图片新标签查看. library(tidyverse)library(nlme)library(fable)library(tsibble)library(fpc)library(reshape2)library(purrr)library(dendextend)library(RColorBrewer)1.整理清洗数据 产看所有离散变量分布
scheme &amp;lt;- read.csv(&amp;quot;1.csv&amp;quot;,stringsAsFactors = FALSE)apply(scheme[,c(2:11)],2,unique)$包.提[1] &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; &amp;quot;18&amp;quot; &amp;quot;8&amp;quot; &amp;quot;6&amp;quot; &amp;quot;/&amp;quot; &amp;quot;5&amp;quot; &amp;quot;24&amp;quot; &amp;quot;&amp;quot; &amp;quot;32&amp;quot; &amp;quot;1&amp;quot; &amp;quot;10&amp;quot;$提.箱[1] &amp;quot;16&amp;quot; &amp;quot;1&amp;quot; &amp;quot;6&amp;quot; &amp;quot;4&amp;quot; &amp;quot;8&amp;quot; &amp;quot;10&amp;quot; &amp;quot;3&amp;quot; &amp;quot;/&amp;quot; &amp;quot;2&amp;quot; &amp;quot;&amp;quot; &amp;quot;5&amp;quot; &amp;quot;24&amp;quot; &amp;quot;18&amp;quot; &amp;quot;12&amp;quot;$纸长mm[1] &amp;quot;160&amp;quot; &amp;quot;153&amp;quot; &amp;quot;189&amp;quot; &amp;quot;133&amp;quot; &amp;quot;/&amp;quot; &amp;quot;140&amp;quot;$纸宽mm[1] &amp;quot;195&amp;quot; &amp;quot;/&amp;quot; $层数[1] &amp;quot;4&amp;quot; &amp;quot;3&amp;quot; &amp;quot;2&amp;quot; &amp;quot;/&amp;quot;$成品定量.g...[1] &amp;quot;13.5&amp;quot; &amp;quot;13&amp;quot; &amp;quot;15&amp;quot; &amp;quot;11&amp;quot; &amp;quot;/&amp;quot; &amp;quot;12&amp;quot; &amp;quot;14.</description>
    </item>
    
    <item>
      <title>SVM, e1071包</title>
      <link>https://nexusal.github.io/svm/</link>
      <pubDate>Thu, 06 Aug 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/svm/</guid>
      <description>拿泰坦尼克号的的数据做测试 library(e1071)m_svm &amp;lt;- svm(Survived ~ . , cost = 100, gamma = 1,data = m_titanic) R里面的SVM使用十分便捷, 开发作者对模型拟合预测的相关函数和常规的其他模型拟合函数保持了一致, 即formula,data, predict也是同理 默认选择高斯径向基函数核, 两个参数, C ,gamma 可以直接指定 根据公式里指定的响应变量的类型(factor or not), 自动选择是回归(regression) 还是分类(classification)  m_svmCall:svm(formula = Survived ~ ., data = m_titanic, cost = 100, gamma = 1)Parameters:SVM-Type: C-classification SVM-Kernel: radial cost: 100 Number of Support Vectors: 447可以直接在预测结果上计算混淆矩阵 (confusion matrix),如下: svm_pre &amp;lt;- predict(m_svm, m_titanic[,-1])confusionMatrix(m_titanic[,1],svm_pre)#####Confusion Matrix and StatisticsReferencePrediction 0 10 536 131 59 283Accuracy : 0.</description>
    </item>
    
    <item>
      <title>应用apriori算法, 分析不同技能组合和价格之间的联系</title>
      <link>https://nexusal.github.io/%E6%A2%A6%E5%B9%BB%E5%8F%AC%E5%94%A4%E5%85%BD%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B/apriori%E6%8A%80%E8%83%BD%E4%BB%B7%E6%A0%BC%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB/</link>
      <pubDate>Mon, 03 Aug 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/%E6%A2%A6%E5%B9%BB%E5%8F%AC%E5%94%A4%E5%85%BD%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B/apriori%E6%8A%80%E8%83%BD%E4%BB%B7%E6%A0%BC%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB/</guid>
      <description>library(rjson)library(tidyverse)library(arules)library(magick)library(ggimage)library(hayalbaz)打开之前爬取的数据 explore &amp;lt;- filter(df_pet,price != 0)skill_com &amp;lt;- explore[,21:22]skill_com$id &amp;lt;- 1:231爬取技能名字和数字代号的对应关系 test &amp;lt;- puppet$new(&amp;quot;https://xyq.cbg.163.com/cgi-bin/equipquery.py?act=show_overall_search_pet&amp;quot;)test$click(selector = &amp;quot;#btn_all_skill&amp;quot;,set_focus = FALSE)test$view()asd &amp;lt;- test$get_elements(selector = &amp;quot;#pet_skill_panel img&amp;quot;) %&amp;gt;%html_nodes(&amp;quot;img&amp;quot;) %&amp;gt;%html_attrs() ### get element 之后的是部分网页结构,nodes里面不能再用之前的selector, 点击列表结构查看合适的selectorsymbol &amp;lt;- sapply(asd,str_extract_all,pattern = &amp;quot;\\d+&amp;quot;,simplify = TRUE) %&amp;gt;% unlist()sk_name &amp;lt;- sapply(asd,str_extract_all,pattern = &amp;quot;[\u4e00-\u9fa5]+&amp;quot;,simplify = TRUE) %&amp;gt;% unlist()sk_symbol &amp;lt;- data.frame(symbol = symbol,name= sk_name)提取所有在这个数据集中的技能 sk_set &amp;lt;- skill_com$skill_combination %&amp;gt;% str_split(pattern = &amp;quot;;&amp;quot;) %&amp;gt;% unlist() %&amp;gt;% unique()df_sk &amp;lt;- vector(mode = &amp;quot;list&amp;quot;, length = &amp;quot;94&amp;quot;)names(df_sk) &amp;lt;- c(sk_set, &amp;quot;id&amp;quot;, &amp;quot;price&amp;quot;)skill_loop &amp;lt;- skill_com$skill_combination %&amp;gt;% str_split(pattern = &amp;quot;;&amp;quot;)container &amp;lt;- matrix(nrow = 93,ncol = 231)for (i in 1:231) {hold &amp;lt;- c(sk_set, &amp;quot;price&amp;quot;) %in% skill_loop[[i]]container[,i] &amp;lt;- hold}container &amp;lt;- t(container) %&amp;gt;% as.</description>
    </item>
    
    <item>
      <title>ted</title>
      <link>https://nexusal.github.io/nlp/ted/</link>
      <pubDate>Sun, 19 Jul 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/nlp/ted/</guid>
      <description>recommend that you can open the pictures of this page in another window for more details original data library(tidyverse) library(jsonlite) library(tm) library(tidytext) library(wordcloud) library(gutenbergr) library(textdata) library(igraph) library(ggraph) library(widyr) library(topicmodels) main &amp;lt;- read.csv(&amp;#34;ted_main.csv&amp;#34;) related &amp;lt;- main$related_talks[1] %&amp;gt;% gsub(pattern = &amp;#34;&amp;#39;&amp;#34;,replacement = &amp;#34;\&amp;#34;&amp;#34;) %&amp;gt;% gsub(pattern = &amp;#34;\&amp;#34;s&amp;#34;,replacement = &amp;#34;&amp;#39;s&amp;#34;) %&amp;gt;% gsub(pattern = &amp;#34;\\s&amp;#39;s&amp;#34;,replacement = &amp;#34; \&amp;#34;s&amp;#34;) %&amp;gt;% fromJSON() tags &amp;lt;- main$tags[1] %&amp;gt;% str_extract_all(pattern = &amp;#34;\\w+&amp;#34;) %&amp;gt;% unlist() load the stopwords of english my_stop &amp;lt;- readLines(&amp;#34;english.</description>
    </item>
    
    <item>
      <title>downloading annual report of companies in china</title>
      <link>https://nexusal.github.io/web-crawl/scrape/</link>
      <pubDate>Sat, 18 Jul 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/web-crawl/scrape/</guid>
      <description>library(RSelenium) library(Rwebdriver) library(dplyr) check_handle &amp;lt;- FALSE count &amp;lt;- 0 while(!check_handle || count &amp;gt; 20){ count &amp;lt;- count + 1 windows_handles &amp;lt;- remDr$getWindowHandles() if(length(windows_handles) &amp;lt; 2){ Sys.sleep(1) }else{ check_handle &amp;lt;- TRUE } remDr &amp;lt;-remoteDriver( browserName = &amp;#34;chrome&amp;#34;, remoteServerAddr = &amp;#34;localhost&amp;#34;, port = 4444L) remDr$open() url &amp;lt;-&amp;#34;http://www.cninfo.com.cn/new/index&amp;#34; remDr$navigate(url) library(rvest) webpage &amp;lt;- ead_html(remDr$getPageSource()[[1]][1]) remDr$quit() lirun &amp;lt;- remDr$findElement(using = &amp;#34;css selector&amp;#34;, value = &amp;#34;#common_top_input_obj&amp;#34;) remDr$mouseMoveToLocation(webElement = lirun) lirun$clickElement() remDr$click() webpage &amp;lt;- read_html(remDr$getPageSource()[[1]][1]) nianfen &amp;lt;- remDr$findElement(using = &amp;#34;css selector&amp;#34;, value = &amp;#34;#mainSelect&amp;#34;) nianfen$clickElement() remDr$mouseMoveToLocation(webElement = nianfen) remDr$mouseMoveToLocation(x= 0, y = 500 ,webElement = nianfen) niandu &amp;lt;- remDr$findElement(using = &amp;#34;partial link text&amp;#34;, value = &amp;#34;&amp;#34;) remDr$getWindowPosition(windowId = &amp;#34;current&amp;#34;) remDr$getWindowSize() remDr$getActiveElement() remDr$mouseMoveToLocation(webElement = nianfen) remDr$click(buttonId = 0) remDr$mouseMoveToLocation(x = 0 , y =500) remDr$mouseMoveToLocation(x = 0 , y =30) remDr$click(buttonId = 0) niandu &amp;lt;- remDr$findElement(using = &amp;#34;link text&amp;#34;, value = &amp;#34;&amp;#34;) niandu$clickElement() remDr$mouseMoveToLocation(webElement = niandu) huzhuban &amp;lt;- remDr$findElement(using = &amp;#34;partial link text&amp;#34;, value = &amp;#34;&amp;#34;) remDr$mouseMoveToLocation(webElement = huzhuban) shuru &amp;lt;- remDr$findElement(using = &amp;#34;css selector&amp;#34;, value = &amp;#34;#common_top_input_obj&amp;#34;) wenben &amp;lt;- list(&amp;#34;&amp;#34;, key = &amp;#34;enter&amp;#34;) shuru$sendKeysToElement(wenben) ###code 是股票代码 for (i in 70:3761) { code[[i]] &amp;lt;- paste0(paste0(rep(&amp;#34;0&amp;#34;,6 - nchar(all[i])),collapse = &amp;#34;&amp;#34;),all[i],collapse = &amp;#34;&amp;#34;) } ###########################  remDr$open() url &amp;lt;-&amp;#34;http://www.</description>
    </item>
    
    <item>
      <title>telco customer churn</title>
      <link>https://nexusal.github.io/telco_customer_churn/main/</link>
      <pubDate>Sat, 18 Jul 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/telco_customer_churn/main/</guid>
      <description>original datasets come from kaggle, click here to check you could see the metadata in Data Explorer of every column when you scroll down library(tidyverse) library(tidyselect) library(pROC) library(randomForest) library(caret) library(cowplot) library(ggcorrplot) retention &amp;lt;- read.csv(&amp;#39;WA_Fn-UseC_-Telco-Customer-Churn.csv&amp;#39;,stringsAsFactors = FALSE) ###### checking if there are any missing value  n_miss &amp;lt;- function(x) n &amp;lt;- sum(is.na(x)) return(n) apply(retention,2,n_miss) only totalcharges has 11 missing values, consider we have more than 7000 observations , I&amp;rsquo;m just gonna discard all of these retention &amp;lt;- filter(retention,!</description>
    </item>
    
    <item>
      <title>Netfix</title>
      <link>https://nexusal.github.io/netfix/netfix/</link>
      <pubDate>Tue, 14 Jul 2020 09:30:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/netfix/netfix/</guid>
      <description>the datasets was downloaded from kaggle , you can click this to check out the original datasets library(tidyverse) library(RColorBrewer) Sys.setlocale(&amp;quot;LC_ALL&amp;quot;, &amp;quot;English&amp;quot;) ### to handle the language issue netflix &amp;lt;- read.csv(&amp;quot;netflix_titles.csv&amp;quot;, stringsAsFactors = FALSE) str(netflix) any(is.na(netflix)) netflix$type &amp;lt;- as.factor(netflix$type) netflix$rating &amp;lt;- as.factor(netflix$rating) netflix_year &amp;lt;- netflix %&amp;gt;% group_by(release_year) %&amp;gt;% summarise(n = n()) %&amp;gt;% arrange(desc(n)) ggplot(netflix_year, aes(reorder(release_year, -release_year),n)) + geom_bar(stat = &amp;quot;identity&amp;quot;,fill = &amp;quot;lightblue&amp;quot;)+ theme_bw()+ theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 15))+ labs(x = &amp;quot;year&amp;quot;, y = &amp;quot;number&amp;quot;) released movie or TVshows has a outbreak since we stepped in 21 century.</description>
    </item>
    
    <item>
      <title>cash flow  of four prominent companies(original data filter by lin le)</title>
      <link>https://nexusal.github.io/stock/stock/</link>
      <pubDate>Mon, 13 Jul 2020 16:00:00 +0800</pubDate>
      
      <guid>https://nexusal.github.io/stock/stock/</guid>
      <description>this is our stocks: 603977,国泰集团
002669,康达新材
603601,再升科技
002444,巨星科技
library(tidyverse)library(RColorbrewer)cashflow &amp;lt;- read.csv(&amp;quot;FI_T61.csv&amp;quot;, stringsAsFactors = FALSE, encoding = &amp;quot;UTF-8&amp;quot;)colnames(cashflow)[1] &amp;lt;- &amp;quot;id&amp;quot;core_stock &amp;lt;- c(&amp;quot;603977&amp;quot;,&amp;quot;002669&amp;quot;,&amp;quot;603601&amp;quot;,&amp;quot;002444&amp;quot;)cashflow$id &amp;lt;- as.character(cashflow$id)for (i in 1:72350) {a &amp;lt;- nchar(cashflow[i,1])if(! a == 6 ){cashflow[i,1] &amp;lt;- paste0(paste0(rep(0,6-a),collapse = &amp;quot;&amp;quot;),cashflow[i,1])}else{}}df_core &amp;lt;- filter(cashflow, id %in% core_stock, Typrep == &amp;quot;A&amp;quot;)inputting the industrial of every stock(extract from 同花顺) industrial &amp;lt;- read.csv(&amp;quot;个股当前数据(同花顺导出).csv&amp;quot;, stringsAsFactors = FALSE)industrial[,1] &amp;lt;- str_extract(industrial[,1],pattern = &amp;quot;\\d+&amp;quot;) %&amp;gt;% unlist()industrial &amp;lt;- industrial[c(&amp;quot;代码&amp;quot;,&amp;quot;名称&amp;quot;,&amp;quot;细分行业&amp;quot;,&amp;quot;所属行业&amp;quot;)]colnames(industrial) &amp;lt;- c(&amp;quot;id&amp;quot;,&amp;quot;name&amp;quot;,&amp;quot;sub_industry&amp;quot;,&amp;quot;industry&amp;quot;)df_core &amp;lt;- df_core %&amp;gt;% left_join(industrial)cashflow &amp;lt;- left_join(cashflow, industrial)print the industry of our stocks select(df_core,id,name,sub_industry,industry) %&amp;gt;% distinct(id,.</description>
    </item>
    
  </channel>
</rss>